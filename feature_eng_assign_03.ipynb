{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf33cb38-518d-49a0-a9ae-45e902ee8f81",
   "metadata": {},
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\n",
    "application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacaaff0-e8f7-4540-8efc-b859862d98cb",
   "metadata": {},
   "source": [
    "Min-Max scaling, also known as normalization, is a technique used in data preprocessing to rescale numerical features to a specific range, typically [0, 1]. This is achieved by subtracting the minimum value of the feature and then dividing by the range (i.e., the maximum value minus the minimum value). The formula for Min-Max scaling is:\n",
    "\n",
    "�\n",
    "scaled\n",
    "=\n",
    "�\n",
    "−\n",
    "�\n",
    "min\n",
    "�\n",
    "max\n",
    "−\n",
    "�\n",
    "min\n",
    "X \n",
    "scaled\n",
    "​\n",
    " = \n",
    "X \n",
    "max\n",
    "​\n",
    " −X \n",
    "min\n",
    "​\n",
    " \n",
    "X−X \n",
    "min\n",
    "​\n",
    " \n",
    "​\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15718e1a-6ad0-404c-867b-73b397a5dbfc",
   "metadata": {},
   "source": [
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
    "Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd4160a-6911-427d-a165-b157bd58e35b",
   "metadata": {},
   "source": [
    "unit vector is a method of scaling where it define all the number hvaing a magnitude of 1 \n",
    "x=(3,4)\n",
    "x=underroot(3)*2+(4)*2 = underoot 25 = 5/5=1 it can scale down the data to the magnitude of 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41646dbd-3995-4570-b660-f3d1674f0878",
   "metadata": {},
   "source": [
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\n",
    "example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25606978-9b50-4e8d-a74f-11f8be875799",
   "metadata": {},
   "source": [
    "principal component analysis PCA, or Principal Component Analysis, is a technique used for dimensionality reduction in data analysis and machine learning. It works by finding a set of new axes, called principal components, that capture the maximum variance in the data. These new axes are orthogonal (perpendicular) to each other and are ranked by the amount \n",
    "Example:\n",
    "\n",
    "Let's say we have a dataset with two features, \"Height\" and \"Weight\", and we want to perform PCA to reduce it to one dimension.\n",
    "\n",
    "Standardize the Data: If necessary, we standardize the data to have mean=0 and standard deviation=1.\n",
    "\n",
    "Calculate Covariance Matrix: The covariance matrix is calculated based on the standardized data.\n",
    "\n",
    "Eigenvalue Decomposition: We find the eigenvectors and eigenvalues of the covariance matrix.\n",
    "\n",
    "Select Principal Components: Since we're reducing to one dimension, we select the eigenvector corresponding to the highest eigenvalue as the principal component.\n",
    "\n",
    "Project Data onto New Space: We project the original data onto this single principal component.\n",
    "\n",
    "The result is a one-dimensional representation of the original data that captures the maximum variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46256c2-42bf-4ace-aa76-4af50ee63aa1",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\n",
    "Extraction? Provide an example to illustrate this concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9894bf1-7f7e-4fd2-bda9-5b917f913003",
   "metadata": {},
   "source": [
    "CA (Principal Component Analysis) is a technique that can be used for feature extraction. Feature extraction involves reducing the dimensionality of a dataset by transforming the original features into a new set of features that capture the most important information.\n",
    "Standardize the Data: Ensure that the data is standardized (mean=0, standard deviation=1) if necessary.\n",
    "\n",
    "Apply PCA: Perform PCA on the standardized data to find the principal components.\n",
    "\n",
    "Select Principal Components: Choose a subset of the principal components based on the amount of variance they explain or other criteria.\n",
    "\n",
    "Project Data onto New Space: Project the original data onto the selected principal components. This results in a lower-dimensional representation of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9b0021-65fc-4a30-bc2d-784b62e543f5",
   "metadata": {},
   "source": [
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset\n",
    "contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\n",
    "preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c74b03f1-25aa-4711-b0d8-5540f58bc583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   price    rating  delivery_time\n",
      "0   0.00  0.368421           0.50\n",
      "1   0.25  0.736842           0.75\n",
      "2   0.50  0.000000           0.25\n",
      "3   0.75  1.000000           1.00\n",
      "4   1.00  0.578947           0.00\n"
     ]
    }
   ],
   "source": [
    "##here i can explain with a code \n",
    "def min_max_scaling(data,feature_min,feature_max): ## defined a class here\n",
    "    x_scaler=(data - feature_min) / (feature_max - feature_min) ## formula for normalization is applied here\n",
    "    return x_scaler\n",
    "import pandas as pd \n",
    "\n",
    "data=pd.DataFrame({    ### here i ahve defined the data\n",
    "    'price': [10, 20, 30, 40, 50],\n",
    "    'rating': [3.5, 4.2, 2.8, 4.7, 3.9],\n",
    "    'delivery_time': [25, 30, 20, 35, 15]\n",
    "})\n",
    "\n",
    "## here we will calculate \n",
    "feature_min = data.min()\n",
    "feature_max = data.max()\n",
    "\n",
    "x_scaler =  min_max_scaling(data,feature_min,feature_max)\n",
    "print(x_scaler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8533109d-021d-44d5-9f77-8d370eac4e75",
   "metadata": {},
   "source": [
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many\n",
    "features, such as company financial data and market trends. Explain how you would use PCA to reduce the\n",
    "dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0564bc37-70ab-428a-8bec-c8b8bc92c51f",
   "metadata": {},
   "source": [
    "\"\"\"in pca also we use two thing \n",
    "1: standardization_ z_score\n",
    "2:min_max_scaler\"\"\"\n",
    "\n",
    "Data Preparation:\n",
    "\n",
    "Gather and preprocess the dataset, including cleaning, handling missing values, and standardizing the data if necessary.\n",
    "Standardize the Data:\n",
    "\n",
    "Standardize the features to have zero mean and unit variance. This step is crucial for PCA as it assumes the data is centered.\n",
    "Covariance Matrix:\n",
    "\n",
    "Calculate the covariance matrix of the standardized features. The covariance matrix gives insights into how features are correlated.\n",
    "Eigenvalue Decomposition:\n",
    "\n",
    "Perform eigenvalue decomposition on the covariance matrix. This yields a set of eigenvectors and their corresponding eigenvalues.\n",
    "Sort Eigenvalues:\n",
    "\n",
    "Sort the eigenvalues in descending order. These eigenvalues represent the amount of variance explained by each corresponding eigenvector.\n",
    "Select Principal Components:\n",
    "\n",
    "Choose the top \n",
    "�\n",
    "k eigenvectors based on the eigenvalues. The number \n",
    "�\n",
    "k of principal components to retain depends on how much variance you want to preserve. Typically, you aim to retain a high percentage of the total variance (e.g., 95%).\n",
    "Projection:\n",
    "\n",
    "Project the original data onto the selected principal components. This involves taking the dot product of the standardized data and the chosen eigenvectors.\n",
    "New Feature Space:\n",
    "\n",
    "The result of the projection is a new feature space that captures the most important information from the original features.\n",
    "Utilize Reduced Dimensionality Data:\n",
    "\n",
    "Use the reduced-dimensionality data as input for your predictive model (e.g., regression model for stock price prediction).\n",
    "PCA is especially useful for high-dimensional\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3569e3-945c-4762-9151-12993799f222",
   "metadata": {},
   "source": [
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\n",
    "values to a range of -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c11a0b17-e78c-46c8-9a7a-cd0504578f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0\n",
      "0  0.000000\n",
      "1  1.000000\n",
      "2  0.210526\n",
      "3  0.473684\n",
      "4  0.736842\n"
     ]
    }
   ],
   "source": [
    "def values(data,feature_min,feature_max): ## defined a class here\n",
    "    x_scaler=(data - feature_min) / (feature_max - feature_min) ## formula for normalization is applied here\n",
    "    return x_scaler\n",
    "import pandas as pd \n",
    "\n",
    "data = pd.DataFrame({ 1, 5, 10, 15, 20\n",
    "                    })\n",
    "\n",
    "feature_min = data.min()\n",
    "feature_max = data.max()\n",
    "\n",
    "x_scaler =  min_max_scaling(data,feature_min,feature_max)\n",
    "print(x_scaler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e501cd11-1438-4e6e-90ff-cf6076fe9939",
   "metadata": {},
   "source": [
    "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform\n",
    "Feature Extraction using PCA. How many principal components would you choose to retain, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d17d9c-0334-46ee-b667-0cb6f3952dd1",
   "metadata": {},
   "source": [
    "When performing feature extraction using PCA, the decision of how many principal components to retain depends on the desired level of information retention and the specific goals of the analysis. One common approach is to retain enough components to capture a high percentage of the total variance, such as 95% or 99%.\n",
    "\n",
    "Without access to the actual data and its characteristics, it's challenging to determine the exact number of principal components to retain. However, I can offer some general guidance based on the features you provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2987ba56-4e8b-49b2-80b4-edd007fdf102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
